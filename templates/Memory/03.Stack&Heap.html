<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stack vs Heap Memory</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #0c0c1d, #1a1a2e);
            color: #e6e6e6;
            line-height: 1.8;
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(15, 15, 25, 0.95);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 0 40px rgba(0, 0, 0, 0.6);
            border: 1px solid #444;
            position: relative;
            overflow: hidden;
        }
        .container::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: radial-gradient(circle at center, transparent 0%, rgba(78, 205, 196, 0.05) 100%);
            pointer-events: none;
        }
        h1, h2, h3 {
            color: #4ecdc4;
            text-align: center;
            margin: 25px 0;
            text-shadow: 0 0 10px rgba(78, 205, 196, 0.3);
        }
        h1 {
            font-size: 2.8em;
            background: linear-gradient(45deg, #4ecdc4, #45b7d1, #ff6b6b);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            padding: 20px 0;
            border-bottom: 3px solid #4ecdc4;
            margin-bottom: 30px;
        }
        .section {
            background: rgba(25, 25, 40, 0.85);
            margin: 30px 0;
            padding: 25px;
            border-radius: 12px;
            border-left: 5px solid #4ecdc4;
            transition: all 0.4s ease;
            position: relative;
            overflow: hidden;
        }
        .section:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.4);
            border-left-color: #ff6b6b;
        }
        .section::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, #4ecdc4, #45b7d1, #ff6b6b);
        }
        .code-block {
            background: #1e1e2d;
            color: #d4d4d4;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            border: 2px solid #333;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 0.95em;
            line-height: 1.6;
            position: relative;
        }
        .code-block::before {
            content: 'CODE';
            position: absolute;
            top: -12px;
            left: 15px;
            background: #4ecdc4;
            color: #0c0c1d;
            padding: 3px 10px;
            border-radius: 5px;
            font-size: 0.8em;
            font-weight: bold;
        }
        .visualization {
            background: #252536;
            padding: 25px;
            border-radius: 10px;
            margin: 25px 0;
            border: 2px solid #45b7d1;
            position: relative;
        }
        .visualization::before {
            content: 'VISUALIZATION';
            position: absolute;
            top: -12px;
            left: 20px;
            background: #45b7d1;
            color: #0c0c1d;
            padding: 3px 12px;
            border-radius: 5px;
            font-size: 0.8em;
            font-weight: bold;
        }
        .memory-visual {
            display: flex;
            flex-direction: column;
            gap: 12px;
            font-family: monospace;
            font-size: 1.1em;
            margin-top: 20px;
        }
        .memory-row {
            display: flex;
            align-items: center;
            padding: 12px;
            background: rgba(60, 60, 80, 0.6);
            border-radius: 6px;
            transition: all 0.3s ease;
            border: 1px solid #555;
        }
        .memory-row:hover {
            background: rgba(70, 70, 90, 0.8);
            transform: translateX(5px);
        }
        .memory-addr {
            width: 150px;
            color: #6a9955;
            font-weight: bold;
            font-size: 1.1em;
        }
        .memory-content {
            flex: 1;
            color: #dcdcaa;
            font-size: 1.1em;
        }
        .memory-status {
            width: 100px;
            text-align: right;
            color: #569cd6;
            font-weight: bold;
            font-size: 1em;
        }
        .highlight {
            background: rgba(78, 205, 196, 0.25);
            padding: 3px 6px;
            border-radius: 4px;
            color: #4ecdc4;
            font-weight: bold;
        }
        .btn {
            background: linear-gradient(45deg, #4ecdc4, #45b7d1);
            color: white;
            border: none;
            padding: 14px 24px;
            margin: 12px 6px;
            border-radius: 30px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
            font-size: 1em;
            box-shadow: 0 4px 15px rgba(78, 205, 196, 0.3);
        }
        .btn:hover {
            transform: scale(1.08);
            box-shadow: 0 0 25px rgba(78, 205, 196, 0.6);
        }
        .btn:active {
            transform: scale(0.95);
        }
        .btn-danger {
            background: linear-gradient(45deg, #ff6b6b, #ff8e8e);
            box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);
        }
        .btn-danger:hover {
            box-shadow: 0 0 25px rgba(255, 107, 107, 0.6);
        }
        .step-indicator {
            display: inline-block;
            background: linear-gradient(45deg, #ff6b6b, #ff8e8e);
            color: white;
            padding: 8px 15px;
            border-radius: 25px;
            font-size: 0.9em;
            margin: 8px;
            font-weight: bold;
            box-shadow: 0 3px 10px rgba(255, 107, 107, 0.3);
        }
        .concept-card {
            background: rgba(40, 40, 60, 0.8);
            padding: 20px;
            margin: 15px 0;
            border-radius: 10px;
            border: 1px solid #555;
            position: relative;
        }
        .concept-card::before {
            content: 'CONCEPT';
            position: absolute;
            top: -10px;
            left: 15px;
            background: #ff6b6b;
            color: white;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 0.7em;
        }
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            background: rgba(30, 30, 45, 0.9);
        }
        .comparison-table th,
        .comparison-table td {
            border: 1px solid #444;
            padding: 15px;
            text-align: left;
        }
        .comparison-table th {
            background: linear-gradient(45deg, #4ecdc4, #45b7d1);
            color: #0c0c1d;
            font-weight: bold;
        }
        .comparison-table tr:nth-child(even) {
            background: rgba(60, 60, 80, 0.6);
        }
        .animation-controls {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 12px;
            margin: 25px 0;
        }
        .progress-bar {
            width: 100%;
            height: 8px;
            background: #333;
            border-radius: 4px;
            overflow: hidden;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4ecdc4, #45b7d1, #ff6b6b);
            width: 0%;
            transition: width 0.8s ease;
            position: relative;
        }
        .progress-fill::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
            animation: shine 2s infinite;
        }
        @keyframes shine {
            0% { transform: translateX(-100%); }
            100% { transform: translateX(100%); }
        }
        .interactive-element {
            background: rgba(50, 50, 70, 0.7);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border: 1px solid #666;
        }
        .memory-usage-meter {
            height: 25px;
            background: #333;
            border-radius: 12px;
            overflow: hidden;
            margin: 15px 0;
            border: 1px solid #555;
        }
        .memory-fill {
            height: 100%;
            background: linear-gradient(90deg, #4ecdc4, #ff6b6b);
            width: 0%;
            transition: width 0.8s ease;
            position: relative;
        }
        .memory-fill::after {
            content: attr(data-percentage);
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: white;
            font-weight: bold;
            text-shadow: 0 0 3px black;
        }
        .toggle-section {
            cursor: pointer;
            background: rgba(60, 60, 80, 0.8);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #4ecdc4;
            transition: all 0.3s ease;
        }
        .toggle-section:hover {
            background: rgba(70, 70, 90, 0.9);
            border-left-color: #ff6b6b;
        }
        .hidden-content {
            display: none;
            padding: 20px;
            background: rgba(40, 40, 60, 0.8);
            margin-top: 15px;
            border-radius: 8px;
            border: 1px solid #555;
            animation: fadeIn 0.5s ease;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .cache-line {
            display: flex;
            background: rgba(60, 60, 80, 0.8);
            margin: 8px 0;
            padding: 12px;
            border-radius: 6px;
            border-left: 4px solid #4ecdc4;
        }
        .cache-block {
            flex: 1;
            background: rgba(80, 80, 100, 0.6);
            margin: 0 3px;
            padding: 10px;
            text-align: center;
            border-radius: 4px;
            transition: all 0.4s ease;
            font-weight: bold;
            border: 1px solid #666;
        }
        .cache-block.active {
            background: rgba(78, 205, 196, 0.5);
            transform: scale(1.15);
            box-shadow: 0 0 15px rgba(78, 205, 196, 0.5);
        }
        .cache-block.hit {
            background: rgba(76, 175, 80, 0.7);
            box-shadow: 0 0 15px rgba(76, 175, 80, 0.5);
        }
        .cache-block.miss {
            background: rgba(244, 67, 54, 0.7);
            box-shadow: 0 0 15px rgba(244, 67, 54, 0.5);
        }
        .explanation-box {
            background: rgba(70, 20, 20, 0.3);
            border-left: 4px solid #ff6b6b;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
        }
        .theoretical-insight {
            background: rgba(20, 70, 20, 0.3);
            border-left: 4px solid #4ecdc4;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
            font-style: italic;
        }
        .deep-dive {
            background: rgba(70, 20, 70, 0.3);
            border-left: 4px solid #ff8e8e;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
        }
        .feynman-box {
            background: rgba(20, 20, 70, 0.3);
            border-left: 4px solid #45b7d1;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 10px 10px 0;
            position: relative;
        }
        .feynman-box::before {
            content: 'FEYNMAN TECHNIQUE';
            position: absolute;
            top: -12px;
            left: 15px;
            background: #45b7d1;
            color: white;
            padding: 2px 10px;
            border-radius: 3px;
            font-size: 0.8em;
            font-weight: bold;
        }
        .simulation-step {
            background: rgba(80, 80, 100, 0.4);
            padding: 15px;
            margin: 10px 0;
            border-radius: 6px;
            border-left: 3px solid #ff6b6b;
        }
        .step-number {
            display: inline-block;
            background: #ff6b6b;
            color: white;
            padding: 5px 12px;
            border-radius: 15px;
            margin-right: 10px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎓 Rio Master's Theoretical Deep Dive: Stack vs Heap Memory Kingdoms 🎓</h1>
        
        <div class="progress-bar">
            <div class="progress-fill" id="progressFill"></div>
        </div>

        <div class="section">
            <h2>🧠 Introduction: The Two Memory Kingdoms - A Theoretical Foundation</h2>
            
            <div class="theoretical-insight">
                <p><strong>Greetings, young programmer!</strong> I am Rio, master of all memory domains. Today we embark on a journey through the two great kingdoms of memory: <span class="highlight">The Stack</span> and <span class="highlight">The Heap</span>.</p>
                <p>This is where most programmers get confused. Let me make it crystal clear through interactive visualizations and deep theoretical understanding.</p>
            </div>

            <div class="deep-dive">
                <h3>Why This Knowledge Matters</h3>
                <p>Understanding memory management is not just about knowing where to store data. It's about comprehending the fundamental architecture of how computers work. Every program you write interacts with these memory systems, and your choices directly impact:</p>
                <ul>
                    <li><strong>Performance:</strong> How fast your program runs</li>
                    <li><strong>Memory Usage:</strong> How much RAM your program consumes</li>
                    <li><strong>Reliability:</strong> Whether your program crashes or runs smoothly</li>
                    <li><strong>Scalability:</strong> How well your program handles large datasets</li>
                </ul>
            </div>

            <div class="interactive-element">
                <button class="btn" onclick="startJourney()">🎯 Begin Theoretical Journey</button>
                <button class="btn" onclick="explainMemoryHierarchy()">📚 Memory Hierarchy Theory</button>
                <button class="btn" onclick="showFoundation()">🏗️ Foundation Concepts</button>
            </div>
        </div>

        <div class="section">
            <h2>🏰 The Stack Kingdom - Theoretical Deep Dive</h2>
            
            <div class="theoretical-insight">
                <h3>What is the Stack? A Mathematical and Computer Science Perspective</h3>
                <p>The stack is not just a memory region - it's a fundamental data structure based on the <span class="highlight">LIFO (Last In, First Out)</span> principle. This principle is mathematically elegant and computationally efficient.</p>
                
                <div class="explanation-box">
                    <p><strong>Mathematical Foundation:</strong> The stack follows the mathematical concept of a "stack" or "pushdown automaton" in theoretical computer science. It's a collection of elements with two primary operations:</p>
                    <ul>
                        <li><strong>Push:</strong> Add an element to the top</li>
                        <li><strong>Pop:</strong> Remove and return the top element</li>
                    </ul>
                </div>
            </div>

            <div class="concept-card">
                <h3>Stack Characteristics - Theoretical Analysis</h3>
                
                <div class="simulation-step">
                    <div class="step-number">1</div>
                    <h4>LIFO (Last In, First Out) - The Fundamental Principle</h4>
                    <p>Mathematically: If elements A, B, C are pushed in order, they are popped in order C, B, A.</p>
                    <p>This creates a natural "nesting" behavior that perfectly matches function call semantics.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">2</div>
                    <h4>Fixed Size - Theoretical Limitation</h4>
                    <p>Stack size is predetermined by the operating system (typically 1-8 MB). This creates a hard mathematical limit on recursion depth.</p>
                    <p>For n levels of recursion: n ≤ stack_size / frame_size</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">3</div>
                    <h4>Automatic Management - Theoretical Efficiency</h4>
                    <p>Managed by the CPU and compiler through the stack pointer register. O(1) operations:</p>
                    <ul>
                        <li>Push: SP = SP - size_of_element</li>
                        <li>Pop: SP = SP + size_of_element</li>
                    </ul>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">4</div>
                    <h4>Contiguous Memory - Theoretical Optimality</h4>
                    <p>Elements are stored sequentially in memory, providing O(1) random access and optimal cache performance.</p>
                </div>
            </div>

            <div class="visualization">
                <h3>Theoretical Stack Memory Model (grows downward ↓)</h3>
                <div id="stackVisualization" class="memory-visual">
                    <!-- Stack visualization will be populated by JavaScript -->
                </div>
                
                <div class="animation-controls">
                    <button class="btn" onclick="simulateFunctionCalls()">🔄 Simulate Function Calls</button>
                    <button class="btn" onclick="clearStack()">🗑️ Clear Stack</button>
                    <button class="btn" onclick="showStepByStep()">📋 Step-by-Step Analysis</button>
                </div>
            </div>

            <div class="feynman-box">
                <h3>Can You Explain Stack Memory to a 5-Year-Old?</h3>
                <p>Imagine a stack of plates in a restaurant. When you add a plate, you put it on top. When you take a plate, you take the top one. The last plate you put on is the first one you take off. That's exactly how computer memory works when it's called a "stack"!</p>
            </div>

            <div class="code-block">
                <!-- Theoretical function call example -->
                // Theoretical model of function call stack
                // Each function call creates a "stack frame" - a theoretical unit of memory
                
                void function_c() {
                    int z = 30;           // Push local variable onto stack
                    printf("%d", z);      // Access local variable
                }                         // Pop from stack (z destroyed) - automatic cleanup
                
                void function_b() {
                    int y = 20;           // Push onto stack
                    function_c();         // Call creates new frame
                    printf("%d", y);      // Access local variable
                }                         // Pop from stack (y destroyed)
                
                void function_a() {
                    int x = 10;           // Push onto stack
                    function_b();         // Call creates new frame
                    printf("%d", x);      // Access local variable
                }                         // Pop from stack (x destroyed)
                
                int main() {
                    function_a();         // Entry point creates first frame
                    return 0;             // Program termination - stack cleared
                }
                
                // Theoretical execution trace:
                // 1. main() frame created: [main variables]
                // 2. function_a() frame created: [main | x=10 | return_addr_to_main]
                // 3. function_b() frame created: [main | x=10 | ret_addr | y=20 | return_addr_to_a]
                // 4. function_c() frame created: [main | x=10 | ret | y=20 | ret | z=30 | return_addr_to_b]
                // 5. function_c() returns: [main | x=10 | ret | y=20 | ret] (z destroyed)
                // 6. function_b() returns: [main | x=10 | ret] (y destroyed)
                // 7. function_a() returns: [main] (x destroyed)
                // 8. main() returns: [] (stack empty)
            </div>

            <div class="deep-dive">
                <h3>Stack Frame Structure - Theoretical Analysis</h3>
                <p>Each function call creates a theoretical "stack frame" with a specific structure:</p>
                
                <div class="memory-visual">
                    <div class="memory-row">
                        <div class="memory-addr">Frame Pointer (FP)</div>
                        <div class="memory-content">Local variables and temporary storage</div>
                        <div class="memory-status">User Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Saved registers (CPU state)</div>
                        <div class="memory-status">CPU State</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Return address (where to go back)</div>
                        <div class="memory-status">Control Flow</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr">Stack Pointer (SP)</div>
                        <div class="memory-content">Function parameters (arguments)</div>
                        <div class="memory-status">Input Data</div>
                    </div>
                </div>
                
                <p><strong>Theoretical Invariant:</strong> At any point during execution, the stack pointer points to the top of the current frame, and the frame pointer points to the base of the current frame.</p>
            </div>

            <div class="concept-card">
                <h3>What Goes on the Stack - Theoretical Classification</h3>
                <ul>
                    <li><strong>Local variables (primitives):</strong> int, float, char, etc. - stored directly</li>
                    <li><strong>Function parameters:</strong> Arguments passed to functions - copied to stack</li>
                    <li><strong>Return addresses:</strong> Memory addresses to return to - enables function calls</li>
                    <li><strong>Saved register values:</strong> CPU register states - maintains execution context</li>
                    <li><strong>Small structs/objects:</strong> When size is known at compile time</li>
                </ul>
                
                <div class="theoretical-insight">
                    <p><strong>Important Theoretical Distinction:</strong> The stack stores the <em>values</em> of small data types and the <em>references</em> to large data structures. The actual large data lives on the heap.</p>
                </div>
            </div>

            <div class="section">
                <h3>Stack Theoretical Advantages</h3>
                
                <div class="simulation-step">
                    <div class="step-number">A1</div>
                    <h4>Mathematical Efficiency: O(1) Operations</h4>
                    <p><strong>Theoretical Foundation:</strong> Stack operations are O(1) because they only require adjusting a single pointer (the stack pointer).</p>
                    <ul>
                        <li><strong>Allocation:</strong> SP = SP - size → O(1)</li>
                        <li><strong>Deallocation:</strong> SP = SP + size → O(1)</li>
                        <li><strong>Access:</strong> Direct calculation → O(1)</li>
                    </ul>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">A2</div>
                    <h4>Automatic Memory Management - Theoretical Safety</h4>
                    <p>The compiler generates code that automatically cleans up stack memory, creating a theoretical guarantee against memory leaks for stack-allocated data.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">A3</div>
                    <h4>Cache Locality - Theoretical Performance</h4>
                    <p>Contiguous memory layout provides optimal cache performance due to spatial locality, theoretically maximizing CPU cache hit rates.</p>
                </div>
            </div>

            <div class="section">
                <h3>Stack Theoretical Disadvantages</h3>
                
                <div class="simulation-step">
                    <div class="step-number">D1</div>
                    <h4>Size Limitation - Theoretical Bound</h4>
                    <p>Fixed stack size creates a mathematical limit: n ≤ stack_size / average_frame_size, where n is maximum recursion depth.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">D2</div>
                    <h4>Scope Limitation - Theoretical Constraint</h4>
                    <p>Data is automatically destroyed when function returns, creating a theoretical limitation for data that must persist beyond function scope.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">D3</div>
                    <h4>Fixed Size Arrays - Theoretical Restriction</h4>
                    <p>Array sizes must be known at compile time, creating a theoretical limitation for dynamic-sized data.</p>
                </div>
            </div>

            <div class="interactive-element">
                <h3>Stack Overflow Theoretical Example:</h3>
                <div class="code-block">
                    def infinite_recursion(n):
                        print(n)
                        return infinite_recursion(n + 1)   # Never stops!
                    
                    infinite_recursion(0)
                     # Theoretical analysis:
                     # Each call adds a frame to stack
                     # Stack depth increases by 1 each call
                     # When stack_depth * frame_size > stack_limit
                     # Stack overflow occurs: "RecursionError"
                </div>
                
                <button class="btn btn-danger" onclick="simulateStackOverflow()">⚠️ Simulate Theoretical Overflow</button>
                <div id="overflowResult"></div>
            </div>
        </div>

        <div class="section">
            <h2>🏔️ The Heap Kingdom - Theoretical Deep Dive</h2>
            
            <div class="theoretical-insight">
                <h3>What is the Heap? A Theoretical Computer Science Perspective</h3>
                <p>The heap is not just a memory region - it's a complex data structure that provides dynamic memory allocation. Unlike the stack's rigid LIFO structure, the heap offers flexible, on-demand allocation.</p>
                
                <div class="explanation-box">
                    <p><strong>Theoretical Foundation:</strong> The heap implements a dynamic memory allocation system that must solve the complex problem of efficiently managing variable-sized blocks of memory while minimizing fragmentation and maximizing performance.</p>
                </div>
            </div>

            <div class="concept-card">
                <h3>Heap Characteristics - Theoretical Analysis</h3>
                
                <div class="simulation-step">
                    <div class="step-number">1</div>
                    <h4>No Automatic Cleanup - Theoretical Responsibility</h4>
                    <p>Unlike the stack, the heap requires explicit memory management. The programmer must manually call free/delete, creating a theoretical responsibility model.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">2</div>
                    <h4>Large Size - Theoretical Scalability</h4>
                    <p>Size limited only by available RAM, theoretically allowing allocation of gigabytes of memory.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">3</div>
                    <h4>Slower Allocation - Theoretical Complexity</h4>
                    <p>Must search for suitable memory blocks, making allocation O(log n) or worse, where n is the number of free blocks.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">4</div>
                    <h4>Random Access - Theoretical Distribution</h4>
                    <p>Data can be allocated anywhere in the heap, creating a theoretical distribution that may not be cache-friendly.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">5</div>
                    <h4>Persistence - Theoretical Lifetime</h4>
                    <p>Data survives function returns, creating a theoretical lifetime model that extends beyond function scope.</p>
                </div>
            </div>

            <div class="visualization">
                <h3>Theoretical Heap Memory Model</h3>
                <div id="heapVisualization" class="memory-visual">
                    <div class="memory-row">
                        <div class="memory-addr">0x00000000</div>
                        <div class="memory-content">Object A (allocated) - Theoretical Block 1</div>
                        <div class="memory-status">USED</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">(free space) - Available for allocation</div>
                        <div class="memory-status">FREE</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Array B (allocated) - Theoretical Block 2</div>
                        <div class="memory-status">USED</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Object C (allocated) - Theoretical Block 3</div>
                        <div class="memory-status">USED</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">(free space) - Fragmented area</div>
                        <div class="memory-status">FREE</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Object D (allocated) - Theoretical Block 4</div>
                        <div class="memory-status">USED</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr">0xFFFFFFFF</div>
                        <div class="memory-content">(free space) - Available space</div>
                        <div class="memory-status">FREE</div>
                    </div>
                </div>
            </div>

            <div class="code-block">
                // Theoretical heap allocation model
                int main() {
                    // Stack allocation - automatic, fast
                    int x = 5;  // x stored on stack, destroyed when main() returns
                    
                    // Heap allocation - manual, flexible
                    int* ptr = (int*)malloc(sizeof(int) * 100);  // Request 100 integers from heap
                    // malloc() searches heap for suitable block, returns pointer
                    
                    ptr[0] = 10;  // Store data at heap location
                    ptr[1] = 20;  // Store more data
                    
                    // Manual cleanup required - theoretical responsibility
                    free(ptr);  // Return memory to heap for reuse
                    
                    return 0;  // Stack cleanup automatic, heap cleanup manual
                }
                
                // Theoretical malloc() process:
                // 1. Calculate requested size: 100 * sizeof(int) = 400 bytes
                // 2. Search heap for free block ≥ 400 bytes
                // 3. Mark found block as allocated
                // 4. Update metadata structures
                // 5. Return pointer to user-accessible memory
                // 6. User responsible for calling free() later
            </div>

            <div class="deep-dive">
                <h3>Theoretical malloc() Process Analysis</h3>
                
                <div class="simulation-step">
                    <div class="step-number">Step 1</div>
                    <p><strong>Size Calculation:</strong> malloc(400) called (100 ints × 4 bytes)</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">Step 2</div>
                    <p><strong>Search Algorithm:</strong> Heap allocator searches free list for suitable block</p>
                    <p>Theoretical approaches: First-fit, Best-fit, Worst-fit, Buddy system, etc.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">Step 3</div>
                    <p><strong>Block Allocation:</strong> Found block at 0x20000000 marked as allocated</p>
                    <p>Metadata updated: size=400, allocated=true, next_free_pointer, etc.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">Step 4</div>
                    <p><strong>Pointer Return:</strong> Returns pointer to usable memory region</p>
                    <p>Memory map updated: [0x20000000: allocated block of 400 bytes]</p>
                </div>
            </div>

            <div class="feynman-box">
                <h3>Can You Explain Heap Memory to a Parking Lot Manager?</h3>
                <p>Imagine a parking lot where cars (data) can park anywhere there's space. Unlike a structured parking garage (stack) where cars go in and out in order, this lot allows cars to park wherever they fit, and drivers (programs) must remember where they parked (keep track of pointers). When they leave, they must tell the manager which spot to free up, or that spot stays reserved forever!</p>
            </div>

            <div class="concept-card">
                <h3>Heap Allocation Strategies - Theoretical Analysis</h3>
                
                <h4>1. First Fit - Theoretical Approach:</h4>
                <div class="simulation-step">
                    <div class="step-number">O(n)</div>
                    <p><strong>Algorithm:</strong> Find FIRST block large enough</p>
                    <p>Theoretical example: Free list: [50 bytes] → [100 bytes] → [200 bytes]<br>
                    Request: 75 bytes<br>
                    Result: Use [100 bytes] block, split if needed<br>
                    <strong>Time Complexity:</strong> O(n) where n is number of free blocks<br>
                    <strong>Space Efficiency:</strong> Moderate - may leave large fragments</p>
                </div>
                
                <h4>2. Best Fit - Theoretical Approach:</h4>
                <div class="simulation-step">
                    <div class="step-number">O(n)</div>
                    <p><strong>Algorithm:</strong> Find SMALLEST block large enough</p>
                    <p>Theoretical example: Free list: [50 bytes] → [100 bytes] → [200 bytes]<br>
                    Request: 75 bytes<br>
                    Result: Use [100 bytes] block (wastes only 25 bytes)<br>
                    <strong>Time Complexity:</strong> O(n) - must search entire list<br>
                    <strong>Space Efficiency:</strong> High - minimizes waste</p>
                </div>
                
                <h4>3. Worst Fit - Theoretical Approach:</h4>
                <div class="simulation-step">
                    <div class="step-number">O(n)</div>
                    <p><strong>Algorithm:</strong> Find LARGEST block</p>
                    <p>Theoretical example: Free list: [50 bytes] → [100 bytes] → [200 bytes]<br>
                    Request: 75 bytes<br>
                    Result: Use [200 bytes] block (leaves 125 bytes for future use)<br>
                    <strong>Time Complexity:</strong> O(n) - must search entire list<br>
                    <strong>Space Efficiency:</strong> Variable - may reduce fragmentation for large requests</p>
                </div>
            </div>

            <div class="section">
                <h3>Theoretical Memory Fragmentation Analysis</h3>
                
                <div class="theoretical-insight">
                    <p><strong>Fragmentation</strong> is a fundamental theoretical problem in heap management. It occurs when free memory is divided into small, non-contiguous blocks, preventing allocation of larger contiguous blocks.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">F1</div>
                    <h4>External Fragmentation - Theoretical Definition</h4>
                    <p>Total free memory exists but is not contiguous. Theoretical formula:</p>
                    <p>Fragmentation = (Total Free Space - Largest Contiguous Free Block) / Total Memory</p>
                    <div class="memory-visual">
                        <div class="memory-row">
                            <div class="memory-addr">Initial State:</div>
                            <div class="memory-content">[████ Object A 100 ████][████ Object B 100 ████][████ Object C 100 ████]</div>
                        </div>
                        <div class="memory-row">
                            <div class="memory-addr">After freeing B:</div>
                            <div class="memory-content">[████ Object A 100 ████][---- FREE 100 ----][████ Object C 100 ████]</div>
                        </div>
                        <div class="memory-row">
                            <div class="memory-addr">Request 250 bytes:</div>
                            <div class="memory-content">Cannot satisfy! Only 100 bytes contiguous available</div>
                        </div>
                    </div>
                    <p><strong>Theoretical Impact:</strong> Reduces effective memory utilization despite available space.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">F2</div>
                    <h4>Internal Fragmentation - Theoretical Definition</h4>
                    <p>Allocated blocks are larger than requested due to alignment or metadata overhead.</p>
                    <p>Theoretical formula: Internal Fragmentation = Allocated Size - Requested Size</p>
                </div>
            </div>

            <div class="concept-card">
                <h3>What Goes on the Heap - Theoretical Classification</h3>
                <ul>
                    <li><strong>Dynamic arrays:</strong> Resizable containers that grow/shrink as needed</li>
                    <li><strong>Linked lists:</strong> Nodes allocated individually as needed</li>
                    <li><strong>Trees:</strong> Node-based structures with dynamic growth</li>
                    <li><strong>Graphs:</strong> Complex structures with dynamic connections</li>
                    <li><strong>Large objects:</strong> Data too large for stack allocation</li>
                    <li><strong>Persistent objects:</strong> Data that must outlive function scope</li>
                </ul>
            </div>

            <div class="section">
                <h3>Heap Theoretical Advantages</h3>
                
                <div class="simulation-step">
                    <div class="step-number">HA1</div>
                    <h4>Theoretical Flexibility</h4>
                    <p>Can allocate any amount of memory up to system limits, providing theoretical unlimited scalability.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">HA2</div>
                    <h4>Theoretical Persistence</h4>
                    <p>Data survives function returns, enabling theoretical object lifetime management beyond scope.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">HA3</div>
                    <h4>Theoretical Large-Scale Allocation</h4>
                    <p>Can allocate gigabytes of memory theoretically, limited only by available RAM.</p>
                </div>
            </div>

            <div class="section">
                <h3>Heap Theoretical Disadvantages</h3>
                
                <div class="simulation-step">
                    <div class="step-number">HD1</div>
                    <h4>Theoretical Complexity</h4>
                    <p>Allocation requires complex search algorithms, making it slower than stack allocation.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">HD2</div>
                    <h4>Theoretical Manual Management</h4>
                    <p>Requires explicit memory management, creating potential for memory leaks and dangling pointers.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">HD3</div>
                    <h4>Theoretical Fragmentation</h4>
                    <p>Memory becomes fragmented over time, reducing effective memory utilization.</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">HD4</div>
                    <h4>Theoretical Cache Performance</h4>
                    <p>Random memory addresses reduce cache hit rates compared to contiguous stack allocation.</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>⚖️ Stack vs Heap - Theoretical Comparison Framework</h2>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Theoretical Aspect</th>
                        <th>Stack</th>
                        <th>Heap</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Time Complexity (Allocation)</td>
                        <td>O(1) - Simple pointer arithmetic</td>
                        <td>O(log n) - Search for suitable block</td>
                    </tr>
                    <tr>
                        <td>Time Complexity (Deallocation)</td>
                        <td>O(1) - Simple pointer arithmetic</td>
                        <td>O(1) - Mark as free, may trigger coalescing</td>
                    </tr>
                    <tr>
                        <td>Space Complexity</td>
                        <td>Fixed size (typically 1-8MB)</td>
                        <td>Dynamic (limited by available RAM)</td>
                    </tr>
                    <tr>
                        <td>Management Model</td>
                        <td>Automatic (compiler/runtime)</td>
                        <td>Manual (programmer responsibility)</td>
                    </tr>
                    <tr>
                        <td>Data Lifetime</td>
                        <td>Function scope (automatic destruction)</td>
                        <td>Persistent (manual destruction required)</td>
                    </tr>
                    <tr>
                        <td>Memory Layout</td>
                        <td>Contiguous, sequential</td>
                        <td>Scattered, non-sequential</td>
                    </tr>
                    <tr>
                        <td>Cache Performance</td>
                        <td>Optimal (spatial locality)</td>
                        <td>Suboptimal (random access)</td>
                    </tr>
                    <tr>
                        <td>Theoretical Safety</td>
                        <td>High (automatic cleanup prevents leaks)</td>
                        <td>Low (manual management creates risks)</td>
                    </tr>
                    <tr>
                        <td>Scalability</td>
                        <td>Limited (fixed size)</td>
                        <td>High (dynamic allocation)</td>
                    </tr>
                    <tr>
                        <td>Use Case</h3>
                        <td>Local variables, function parameters, small data</td>
                        <td>Dynamic data structures, large objects, persistent data</td>
                    </tr>
                </tbody>
            </table>

            <div class="feynman-box">
                <h3>Theoretical Framework for Decision Making</h3>
                <p>When deciding between stack and heap allocation, consider these theoretical criteria:</p>
                <ol>
                    <li><strong>Size Prediction:</strong> Known at compile time? → Stack. Variable? → Heap.</li>
                    <li><strong>Lifetime Requirements:</strong> Function-scoped? → Stack. Persistent? → Heap.</li>
                    <li><strong>Performance Needs:</strong> High-performance? → Stack. Flexibility needed? → Heap.</li>
                    <li><strong>Memory Constraints:</strong> Small data? → Stack. Large data? → Heap.</li>
                </ol>
            </div>

            <div class="code-block">
                // Theoretical comparison example
                def stack_example():
                    # Theoretical analysis:
                    # - Size: 3 elements (known at compile time)
                    # - Lifetime: Function scope
                    # - Performance: O(1) allocation/deallocation
                    # - Safety: Automatic cleanup
                    x = 10                     # Stack allocation
                    y = [1, 2, 3]             # Reference on stack, data on heap
                    
                    # Theoretical execution:
                    # 1. x allocated on stack: O(1)
                    # 2. y reference allocated on stack: O(1)
                    # 3. [1,2,3] allocated on heap: O(log n)
                    # 4. Function returns: x destroyed (O(1)), y reference destroyed (O(1))
                    # 5. [1,2,3] remains on heap for garbage collection

                def heap_example():
                    # Theoretical analysis:
                    # - Size: Dynamic (could grow)
                    # - Lifetime: May outlive function
                    # - Performance: O(log n) allocation
                    # - Responsibility: Manual cleanup required
                    my_list = [1, 2, 3]       # List object on heap
                    my_dict = {'a': 1}        # Dict object on heap
                    
                    return my_list            # Return reference to heap object
                    # Theoretical implications:
                    # - my_list reference destroyed (stack)
                    # - But heap objects persist (manual cleanup needed)
                    # - Return provides access to heap data

                result = heap_example()       # Heap object still accessible
                # Theoretical note: Garbage collector handles cleanup
            </div>
        </div>

        <div class="section">
            <h2>🏗️ Complete Memory Layout - Theoretical Architecture</h2>
            
            <div class="theoretical-insight">
                <h3>Program Memory Layout - Theoretical Model</h3>
                <p>When a program executes, the operating system creates a theoretical memory layout with distinct regions, each serving specific purposes in the computer's architecture.</p>
            </div>

            <div class="visualization">
                <h3>Theoretical Memory Map Architecture</h3>
                <div class="memory-visual">
                    <div class="memory-row">
                        <div class="memory-addr">0xFFFFFFFF</div>
                        <div class="memory-content">Command Line Arguments & Environment Variables - Program inputs</div>
                        <div class="memory-status">User Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">STACK (grows downward ↓) - Local variables, function calls, execution context</div>
                        <div class="memory-status">Runtime Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">(free space) - Available for runtime growth</div>
                        <div class="memory-status">Available</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">HEAP (grows upward ↑) - Dynamic allocations, runtime data structures</div>
                        <div class="memory-status">Runtime Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">BSS Segment - Uninitialized global/static variables (zero-initialized by OS)</div>
                        <div class="memory-status">Static Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr"></div>
                        <div class="memory-content">Data Segment - Initialized global/static variables</div>
                        <div class="memory-status">Static Data</div>
                    </div>
                    <div class="memory-row">
                        <div class="memory-addr">0x00000000</div>
                        <div class="memory-content">Text Segment - Machine code, executable instructions (READ-ONLY)</div>
                        <div class="memory-status">Code</div>
                    </div>
                </div>
                
                <div class="theoretical-insight">
                    <p><strong>Theoretical Architecture:</strong> Stack and Heap grow toward each other, creating a theoretical "sandwich" model where the program's static components (Text, Data, BSS) are at the bottom, and runtime components (Stack, Heap) are at the top, with free space in the middle.</p>
                </div>
            </div>

            <div class="code-block">
                // Theoretical program example with memory layout
                #include <stdio.h>
                #include <stdlib.h>
                
                // Theoretical placement: Data Segment (initialized global)
                int initialized_global = 42;  // Memory address: 0x00601030 (example)
                
                // Theoretical placement: BSS Segment (uninitialized global) 
                int uninitialized_global;     // Memory address: 0x00601034 (example)
                
                // Theoretical placement: Text Segment (compiled code)
                int main() {
                    // Theoretical placement: Stack
                    int local_var = 10;              // Memory address: 0x7fff5fbff5cc (example)
                    static int static_var = 20;      // Theoretical: Data segment (initialized)
                    
                    // Theoretical placement: Heap
                    int* heap_var = (int*)malloc(sizeof(int));  // Memory address: 0x01a38010 (example)
                    *heap_var = 30;
                    
                    printf("Theoretical memory addresses:\n");
                    printf("Text segment (code):     %p\n", (void*)main);           // Executable code
                    printf("Data segment (init):     %p\n", (void*)&initialized_global); // Initialized globals
                    printf("BSS segment (uninit):    %p\n", (void*)&uninitialized_global); // Zero-initialized globals
                    printf("Stack (local var):       %p\n", (void*)&local_var);     // Local variables
                    printf("Heap (dynamic):          %p\n", (void*)heap_var);       // Dynamic allocation
                    
                    free(heap_var);  // Theoretical cleanup: return memory to heap
                    return 0;
                }
                
                // Theoretical memory layout analysis:
                // - Text segment: Read-only, contains machine code
                // - Data segment: Read-write, contains initialized globals
                // - BSS segment: Read-write, contains uninitialized globals (zeroed by OS)
                // - Heap: Read-write, grows upward, dynamic allocation
                // - Stack: Read-write, grows downward, automatic management
            </div>
        </div>

        <div class="section">
            <h2>📊 How Data Structures Live in Memory - Theoretical Analysis</h2>
            
            <div class="toggle-section" onclick="toggleSection('arrayTheory')">
                <h3>1. Arrays - Theoretical Memory Model</h3>
            </div>
            <div id="arrayTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Arrays: Contiguous Memory - Theoretical Foundation</h4>
                    <p>Arrays are the most theoretically efficient data structure for random access because they provide O(1) access through direct address calculation.</p>
                </div>
                
                <div class="code-block">
                    int arr[5] = {10, 20, 30, 40, 50};
                    
                    // Theoretical memory layout:
                    // Address    Value
                    // 0x1000:    10    (arr[0])
                    // 0x1004:    20    (arr[1])  - 4 bytes per int
                    // 0x1008:    30    (arr[2])
                    // 0x100C:    40    (arr[3])
                    // 0x1010:    50    (arr[4])
                    
                    // Theoretical access formula:
                    // Address of arr[i] = base_address + (i × element_size)
                    // Example: arr[3] address = 0x1000 + (3 × 4) = 0x100C
                    // Value = 40
                    
                    // Theoretical time complexity: O(1) - just arithmetic!
                    
                    // Theoretical advantages:
                    // 1. Direct address calculation - O(1) access
                    // 2. Cache-friendly - spatial locality
                    // 3. No pointer chasing - direct access
                    // 4. Predictable memory access pattern
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T1</div>
                    <h4>Theoretical Performance Analysis</h4>
                    <p><strong>Cache Hit Rate:</strong> For sequential access of n elements in an array that fits in one cache line:</p>
                    <p>Cache hits = n-1, Cache misses = 1, Hit rate = (n-1)/n</p>
                    <p>For n=16 elements: Hit rate = 15/16 = 93.75%</p>
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('linkedTheory')">
                <h3>2. Linked Lists - Theoretical Memory Model</h3>
            </div>
            <div id="linkedTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Linked Lists: Scattered Memory - Theoretical Foundation</h4>
                    <p>Linked lists provide O(1) insertion/deletion but O(n) access due to pointer chasing and lack of spatial locality.</p>
                </div>
                
                <div class="code-block">
                    struct Node {
                        int data;              // 4 bytes
                        struct Node* next;     // 8 bytes (64-bit pointer)
                    };  // Total: 12 bytes + padding = 16 bytes
                    
                    // Theoretical creation:
                    Node* head = createNode(10);      // Allocates node on heap
                    head->next = createNode(20);      // Allocates another node
                    head->next->next = createNode(30); // Allocates third node
                    
                    // Theoretical memory layout (could be anywhere):
                    // Address    Content
                    // 0x2000:    data=10, next=0x3500  (head node)
                    // 0x3500:    data=20, next=0x1200  (second node)  
                    // 0x1200:    data=30, next=NULL    (third node)
                    
                    // Theoretical access to 3rd element:
                    // 1. Start at head (0x2000) - potential cache miss
                    // 2. Follow pointer to 0x3500 - potential cache miss
                    // 3. Follow pointer to 0x1200 - potential cache miss
                    // 4. Read data = 30
                    // Time: O(n) - must traverse
                    // Cache misses: potentially n misses for n elements
                    
                    // Theoretical disadvantages:
                    // 1. Pointer chasing - each node could be anywhere
                    // 2. Cache-unfriendly - each access might be cache miss
                    // 3. Extra memory - 8 bytes per pointer (64-bit)
                    // 4. Memory fragmentation - scattered allocation
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T2</div>
                    <h4>Theoretical Memory Overhead Analysis</h4>
                    <p>For each data element in a linked list:</p>
                    <ul>
                        <li>Data size: sizeof(data_type)</li>
                        <li>Pointer size: 8 bytes (64-bit)</li>
                        <li>Memory overhead ratio: 8 / (8 + sizeof(data_type))</li>
                    </ul>
                    <p>For int (4 bytes): Overhead = 8/(8+4) = 66.7% overhead!</p>
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('matrixTheory')">
                <h3>3. 2D Arrays - Row-Major vs Column-Major Theory</h3>
            </div>
            <div id="matrixTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>2D Arrays: Memory Layout Theory</h4>
                    <p>The memory layout of 2D arrays significantly impacts cache performance and access patterns.</p>
                </div>
                
                <div class="code-block">
                    int matrix[3][4] = {
                        {1,  2,  3,  4},
                        {5,  6,  7,  8},
                        {9, 10, 11, 12}
                    };
                    
                    // Theoretical Row-Major Order (C/C++/Python):
                    // Memory: [1][2][3][4][5][6][7][8][9][10][11][12]
                    // Elements stored row by row
                    // Cache-friendly for row-wise access
                    
                    // Theoretical address calculation:
                    // matrix[i][j] = base + (i × num_cols + j) × element_size
                    // Example matrix[2][1]:
                    // = 0x1000 + (2 × 4 + 1) × 4
                    // = 0x1000 + 9 × 4
                    // = 0x1000 + 36
                    // = 0x1024
                    // Value: 10 ✓
                    
                    // Theoretical cache implications:
                    
                    // BAD: Column-major access in row-major storage
                    for (int col = 0; col < 4; col++) {
                        for (int row = 0; row < 3; row++) {
                            sum += matrix[row][col];  // Jumps 4 ints each time (cache-unfriendly)
                        }
                    }
                    // Access pattern: 1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12
                    // Cache miss rate: Very high!
                    
                    // GOOD: Row-major access in row-major storage
                    for (int row = 0; row < 3; row++) {
                        for (int col = 0; col < 4; col++) {
                            sum += matrix[row][col];  // Sequential access (cache-friendly)
                        }
                    }
                    // Access pattern: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12
                    // Cache hit rate: Very high!
                    
                    // Theoretical performance difference: Up to 10x slower for bad access pattern!
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('structTheory')">
                <h3>4. Structures/Objects - Padding & Alignment Theory</h3>
            </div>
            <div id="structTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Structures: Memory Alignment Theory</h4>
                    <p>Memory alignment requirements create theoretical padding that affects memory usage and performance.</p>
                </div>
                
                <div class="code-block">
                    struct Example {
                        char a;      // 1 byte
                        int b;       // 4 bytes  
                        char c;      // 1 byte
                    };
                    
                    // Theoretical size calculation:
                    // Naive expectation: 1 + 4 + 1 = 6 bytes
                    // Reality: Usually 12 bytes!
                    
                    // Theoretical reason: Memory alignment requirements
                    // - char (1 byte) can be at any address
                    // - int (4 bytes) should be at address divisible by 4 (alignment requirement)
                    // - double (8 bytes) should be at address divisible by 8
                    
                    // Theoretical actual layout:
                    // Address    Content
                    // 0x00:      a (char)          - 1 byte
                    // 0x01:      [padding]         - 3 bytes (to align int)
                    // 0x04:      b (int - byte 1)  - 4 bytes
                    // 0x05:      b (int - byte 2)  - 
                    // 0x06:      b (int - byte 3)  - 
                    // 0x07:      b (int - byte 4)  - 
                    // 0x08:      c (char)          - 1 byte
                    // 0x09:      [padding]         - 3 bytes (to align next struct)
                    // Total: 12 bytes
                    
                    // Theoretical optimization - reordered for efficiency:
                    struct Optimized {
                        int b;       // 4 bytes - largest first
                        char a;      // 1 byte  
                        char c;      // 1 byte
                        // 2 bytes padding for next struct alignment
                    };
                    // Size: 8 bytes (instead of 12!) - 33% memory savings!
                    
                    // Theoretical rule: Order struct members from largest to smallest to minimize padding.
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T3</div>
                    <h4>Theoretical Padding Calculation</h4>
                    <p>For each field in a struct:</p>
                    <ol>
                        <li>Calculate alignment requirement (size of field type)</li>
                        <li>Pad to meet alignment requirement</li>
                        <li>Add field size</li>
                        <li>At end, pad to align next struct</li>
                    </ol>
                    <p>Worst case: Each field requires different alignment → maximum padding.</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>⚡ Cache Optimization & Memory-Efficient Programming - Theoretical Framework</h2>
            
            <div class="theoretical-insight">
                <h3>Cache Theory: The Fundamental Principle</h3>
                <p>Modern CPUs have a theoretical memory hierarchy where cache performance directly impacts program speed. Understanding cache behavior is crucial for theoretical optimization.</p>
            </div>

            <div class="concept-card">
                <h3>Cache Lines and Spatial Locality - Theoretical Foundation</h3>
                
                <div class="simulation-step">
                    <div class="step-number">C1</div>
                    <h4>Theoretical Cache Line Principle</h4>
                    <p>When CPU loads one byte, it theoretically loads an entire cache line (typically 64 bytes) to exploit spatial locality.</p>
                </div>
                
                <div class="code-block">
                    int arr[16];  // 16 ints × 4 bytes = 64 bytes = 1 cache line
                    
                    // Theoretical cache behavior:
                    // When you access arr[0], CPU loads arr[0] through arr[15]
                    // into cache automatically!
                    
                    for (int i = 0; i < 16; i++) {
                        sum += arr[i];  // Theoretical access pattern:
                        // arr[0]: cache miss (loads entire cache line)
                        // arr[1-15]: cache hits (already in cache)
                    }
                    // Theoretical cache hit rate: 15/16 = 93.75%
                    
                    // Theoretical performance gain: 10-100x faster than random access!
                </div>
            </div>

            <div class="interactive-element">
                <h3>Theoretical Cache Line Visualization:</h3>
                <div class="cache-line" id="cacheLineVisual">
                    <div class="cache-block" data-index="0">arr[0]</div>
                    <div class="cache-block" data-index="1">arr[1]</div>
                    <div class="cache-block" data-index="2">arr[2]</div>
                    <div class="cache-block" data-index="3">arr[3]</div>
                    <div class="cache-block" data-index="4">arr[4]</div>
                    <div class="cache-block" data-index="5">arr[5]</div>
                    <div class="cache-block" data-index="6">arr[6]</div>
                    <div class="cache-block" data-index="7">arr[7]</div>
                    <div class="cache-block" data-index="8">arr[8]</div>
                    <div class="cache-block" data-index="9">arr[9]</div>
                    <div class="cache-block" data-index="10">arr[10]</div>
                    <div class="cache-block" data-index="11">arr[11]</div>
                    <div class="cache-block" data-index="12">arr[12]</div>
                    <div class="cache-block" data-index="13">arr[13]</div>
                    <div class="cache-block" data-index="14">arr[14]</div>
                    <div class="cache-block" data-index="15">arr[15]</div>
                </div>
                
                <button class="btn" onclick="simulateCacheAccess()">🎯 Simulate Theoretical Cache Access</button>
                <div id="cacheResult"></div>
            </div>

            <div class="toggle-section" onclick="toggleSection('aossTheory')">
                <h3>Struct of Arrays vs Array of Structs - Theoretical Analysis</h3>
            </div>
            <div id="aossTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Theoretical Memory Layout Impact on Performance</h4>
                    <p>The way data is organized in memory significantly impacts cache performance and theoretical processing efficiency.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical Array of Structs (AoS) - Cache-unfriendly
                    struct Point {
                        float x, y, z;  // 12 bytes + padding
                    };
                    
                    Point points[1000];  // Memory layout: [x0,y0,z0][x1,y1,z1]...[x999,y999,z999]
                    
                    // Process only x coordinates - Theoretical cache behavior:
                    for (int i = 0; i < 1000; i++) {
                        result += points[i].x;  // Theoretical access:
                        // Accesses x, y, z but only uses x
                        // Wastes 2/3 of loaded cache line data
                        // Cache bandwidth utilization: 33% efficient
                    }
                    
                    // Theoretical Struct of Arrays (SoA) - Cache-friendly
                    struct Points {
                        float x[1000];  // All x coordinates together
                        float y[1000];  // All y coordinates together  
                        float z[1000];  // All z coordinates together
                    };
                    
                    Points points;
                    
                    // Process only x coordinates - Theoretical cache behavior:
                    for (int i = 0; i < 1000; i++) {
                        result += points.x[i];  // Theoretical access:
                        // Sequential access - perfect cache utilization
                        // Uses 100% of loaded cache lines
                        // Cache bandwidth utilization: 100% efficient
                    }
                    
                    // Theoretical performance difference: SoA can be 2-3x faster due to cache efficiency!
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('temporalTheory')">
                <h3>Temporal Locality Theory</h3>
            </div>
            <div id="temporalTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Temporal Locality: The Reuse Principle</h4>
                    <p>Theoretical principle: If you access data once, you're likely to access it again soon, so keep it in cache.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical BAD: Poor temporal locality
                    for (int i = 0; i < n; i++) {
                        process_array1(arr[i]);  // Uses arr[i]
                    }
                    for (int i = 0; i < n; i++) {
                        process_array2(arr[i]);  // arr[i] might not be in cache anymore
                        // Theoretical cache behavior: Low reuse rate
                    }
                    
                    // Theoretical GOOD: Excellent temporal locality
                    for (int i = 0; i < n; i++) {
                        process_array1(arr[i]);  // Uses arr[i]
                        process_array2(arr[i]);  // arr[i] definitely still in cache
                        // Theoretical cache behavior: High reuse rate
                    }
                    
                    // Theoretical cache efficiency: 
                    // Bad pattern: O(n) cache misses for arr[i] accesses
                    // Good pattern: O(n) total cache misses (optimal)
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('tilingTheory')">
                <h3>Loop Tiling/Blocking - Advanced Theoretical Technique</h3>
            </div>
            <div id="tilingTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Loop Tiling: Cache-Aware Algorithm Design</h4>
                    <p>Theoretical technique to optimize algorithms for cache performance by processing data in blocks that fit in cache.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical naive matrix multiplication - cache-unfriendly
                    for (int i = 0; i < N; i++) {
                        for (int j = 0; j < N; j++) {
                            for (int k = 0; k < N; k++) {
                                C[i][j] += A[i][k] * B[k][j];  // B accessed column-wise
                            }
                        }
                    }
                    // Theoretical cache behavior: 
                    // B matrix accessed in column-major order (cache-unfriendly)
                    // Poor spatial locality for B matrix
                    // Cache miss rate: High
                    
                    // Theoretical blocked/tiled matrix multiplication - cache-optimized
                    #define BLOCK_SIZE 64
                    for (int ii = 0; ii < N; ii += BLOCK_SIZE) {
                        for (int jj = 0; jj < N; jj += BLOCK_SIZE) {
                            for (int kk = 0; kk < N; kk += BLOCK_SIZE) {
                                // Process BLOCK_SIZE × BLOCK_SIZE submatrix
                                for (int i = ii; i < min(ii+BLOCK_SIZE, N); i++) {
                                    for (int j = jj; j < min(jj+BLOCK_SIZE, N); j++) {
                                        for (int k = kk; k < min(kk+BLOCK_SIZE, N); k++) {
                                            C[i][j] += A[i][k] * B[k][j];
                                        }
                                    }
                                }
                            }
                        }
                    }
                    // Theoretical cache behavior:
                    // Submatrices fit in cache
                    // Better data reuse
                    // Cache miss rate: Significantly reduced
                    // Theoretical performance improvement: 5-10x faster!
                </div>
            </div>
        </div>

        <div class="section">
            <h2>🔧 Memory-Efficient Programming Techniques - Theoretical Framework</h2>
            
            <div class="toggle-section" onclick="toggleSection('bitPackingTheory')">
                <h3>1. Bit Packing - Theoretical Space Optimization</h3>
            </div>
            <div id="bitPackingTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Bit Packing: Theoretical Space-Time Tradeoff</h4>
                    <p>Theoretical technique to pack multiple small values into fewer memory units, trading computation time for space.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical BAD: Space-inefficient boolean storage
                    flags = [0, 1, 0, 1, 1, 0, 1, 0]   // 8 ints × 4 bytes = 32 bytes
                    // Theoretical space usage: 8× space overhead
                    
                    // Theoretical GOOD: Bit packing - space-efficient storage
                    flags = 0b01011010   // 1 byte! (8 bits packed into 1 byte)
                    // Theoretical space usage: 32× space efficiency
                    
                    // Theoretical bit operations:
                    // Set bit i: flags |= (1 << i)     - O(1) operation
                    // Clear bit i: flags &= ~(1 << i)  - O(1) operation  
                    // Check bit i: (flags >> i) & 1    - O(1) operation
                    
                    // Theoretical tradeoff: Space saved vs. Computation time increased
                    // For 8 booleans: 32 bytes → 1 byte (97% space savings)
                    // But each access requires bit manipulation operations
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('stringInterningTheory')">
                <h3>2. String Interning - Theoretical Memory Management</h3>
            </div>
            <div id="stringInterningTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>String Interning: Theoretical Memory Deduplication</h4>
                    <p>Theoretical technique to reduce memory usage by storing identical strings only once and sharing references.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical BAD: Multiple copies of same string
                    names = ["Alice"] * 1000   // 1000 separate "Alice" strings
                    // Theoretical memory usage: 1000 × 6 bytes = 6000 bytes
                    
                    // Theoretical GOOD: String interning
                    // Only 1 "Alice" string stored, 1000 references to it
                    // Theoretical memory usage: 6 bytes + 1000 pointers = ~8006 bytes
                    // Wait, that's worse! But...
                    
                    // Theoretical real benefit: Comparison operations
                    // Without interning: strcmp(str1, str2) = O(n) - compare character by character
                    // With interning: str1 == str2 (pointer comparison) = O(1) - compare addresses
                    
                    // Theoretical time complexity improvement: O(n) → O(1) for equality checks
                    // Theoretical memory usage: More complex tradeoff depending on usage patterns
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('memoryPoolingTheory')">
                <h3>3. Memory Pooling - Theoretical Allocation Optimization</h3>
            </div>
            <div id="memoryPoolingTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Memory Pooling: Theoretical Allocation Strategy</h4>
                    <p>Theoretical technique to pre-allocate memory blocks to avoid allocation overhead and fragmentation.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical BAD: Frequent allocation/deallocation
                    for (int i = 0; i < 1000000; i++) {
                        Node* n = malloc(sizeof(Node));  // Theoretical cost: O(log n) or worse
                        process(n);                      // Use the node
                        free(n);                         // Theoretical cost: O(1) but causes fragmentation
                    }
                    // Theoretical total cost: 1,000,000 × (malloc + free) operations
                    
                    // Theoretical GOOD: Pre-allocate pool
                    Node pool[1000];           // Pre-allocated block
                    int pool_index = 0;        // Simple index-based allocation
                    
                    Node* allocate_node() {    // Theoretical allocation: O(1)
                        if (pool_index < 1000) {
                            return &pool[pool_index++];  // Direct array access
                        }
                        return NULL;  // Pool exhausted
                    }
                    
                    // Theoretical benefits:
                    // - No fragmentation: All memory allocated upfront
                    // - Fast allocation: O(1) array access
                    // - Predictable memory usage: Fixed size pool
                    // - Theoretical performance: 100x+ faster allocation
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('lazyEvalTheory')">
                <h3>4. Lazy Evaluation - Theoretical Computation Optimization</h3>
            </div>
            <div id="lazyEvalTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Lazy Evaluation: Theoretical Computation Strategy</h4>
                    <p>Theoretical technique to defer computation until needed, optimizing memory usage and performance.</p>
                </div>
                
                <div class="code-block">
                    // Theoretical BAD: Eager evaluation - compute everything upfront
                    def compute_all_permutations(arr):
                        result = []
                        # Theoretical: Generate ALL n! permutations
                        # For n=10: 10! = 3,628,800 permutations
                        # Theoretical memory usage: Gigabytes for large n
                        generate(arr, 0, result)
                        return result
                    
                    # Theoretical memory complexity: O(n! × n) - factorial space
                    # Theoretical time complexity: O(n! × n) - factorial time
                    
                    // Theoretical GOOD: Lazy evaluation - compute on demand
                    def compute_permutations_lazy(arr):
                        def generate_next():
                            # Theoretical: Yield one permutation at a time
                            # Memory usage: O(n) for each permutation
                            yield next_permutation()
                        
                        return generate_next()
                    
                    # Theoretical benefits:
                    # Memory complexity: O(n) - constant space
                    # Time complexity: O(n) per permutation when needed
                    # Theoretical space efficiency: 1000s of times better for large datasets
                </div>
            </div>
        </div>

        <div class="section">
            <h2>⚠️ Memory Profiling & Theoretical Problem Analysis</h2>
            
            <div class="toggle-section" onclick="toggleSection('memoryLeaksTheory')">
                <h3>1. Memory Leaks - Theoretical Resource Management</h3>
            </div>
            <div id="memoryLeaksTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Memory Leaks: Theoretical Resource Management Failure</h4>
                    <p>Theoretical problem where allocated memory is not freed, causing unbounded memory growth.</p>
                </div>
                
                <div class="code-block">
                    void leak_example() {
                        int* ptr = malloc(1000 * sizeof(int));  // Allocate 4000 bytes
                        // ... use ptr ...
                        // Theoretical error: Forgot to call free(ptr)!
                        // Theoretical consequence: 4000 bytes lost forever until program exits
                        // Theoretical impact: Cumulative memory growth with repeated calls
                    }
                    
                    // Theoretical analysis:
                    // Each call to leak_example() leaks 4000 bytes
                    // After n calls: n × 4000 bytes leaked
                    // Memory usage: O(n) growth without bound
                    // Theoretical solution: Always pair malloc with free
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('danglingTheory')">
                <h3>2. Dangling Pointers - Theoretical Memory Safety</h3>
            </div>
            <div id="danglingTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Dangling Pointers: Theoretical Memory Safety Violation</h4>
                    <p>Theoretical problem where a pointer references memory that has been deallocated.</p>
                </div>
                
                <div class="code-block">
                    int* dangling_example() {
                        int x = 42;        // x allocated on stack
                        return &x;         // Theoretical error: return address of stack variable
                    }                      // x destroyed when function returns
                    // Theoretical consequence: Returned pointer points to invalid memory
                    // Theoretical impact: Undefined behavior when pointer is used
                    
                    // Theoretical analysis:
                    // Stack variable x exists only during function execution
                    // When function returns, x's memory is marked as free
                    // Using returned pointer accesses invalid memory
                    // Theoretical solution: Return copies, not addresses of local variables
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('doubleFreeTheory')">
                <h3>3. Double Free - Theoretical Memory Management Error</h3>
            </div>
            <div id="doubleFreeTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Double Free: Theoretical Memory Corruption</h4>
                    <p>Theoretical problem where memory is freed twice, causing heap corruption.</p>
                </div>
                
                <div class="code-block">
                    int* ptr = malloc(sizeof(int));  // Allocate memory
                    free(ptr);                       // Free memory (valid)
                    free(ptr);                       // Theoretical error: freeing already-freed memory!
                    
                    // Theoretical analysis:
                    // First free(): Marks memory as available in heap management structures
                    // Second free(): Tries to mark already-free memory as free again
                    // Theoretical consequence: Heap management structures corrupted
                    // Theoretical impact: Undefined behavior, potential crashes
                </div>
            </div>

            <div class="toggle-section" onclick="toggleSection('bufferOverflowTheory')">
                <h3>4. Buffer Overflow - Theoretical Memory Boundary Violation</h3>
            </div>
            <div id="bufferOverflowTheory" class="hidden-content">
                <div class="theoretical-insight">
                    <h4>Buffer Overflow: Theoretical Memory Boundary Error</h4>
                    <p>Theoretical problem where data is written beyond allocated memory boundaries.</p>
                </div>
                
                <div class="code-block">
                    char buffer[10];                           // 10-byte buffer allocated
                    strcpy(buffer, "This string is way too long!");  // Write 37 characters
                    // Theoretical error: Writes past buffer[9] boundary
                    // Theoretical consequence: Overwrites adjacent memory
                    // Theoretical impact: Memory corruption, potential security vulnerabilities
                    
                    // Theoretical analysis:
                    // Buffer size: 10 bytes [0-9]
                    // String length: 37 characters + null terminator = 38 bytes needed
                    // Bytes written beyond boundary: 38 - 10 = 28 bytes
                    // Theoretical damage: 28 bytes of adjacent memory corrupted
                    // Theoretical solution: Bounds checking, safe string functions
                </div>
            </div>
        </div>

        <div class="section">
            <h2>📊 Memory Budgets - Theoretical Cost Analysis</h2>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Data Structure</th>
                        <th>Theoretical Memory per Element</th>
                        <th>Theoretical Notes</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Array</td>
                        <td>element_size</td>
                        <td>Theoretical: Most efficient, no overhead</td>
                    </tr>
                    <tr>
                        <td>Dynamic Array</td>
                        <td>element_size × 1.5</td>
                        <td>Theoretical: Some wasted capacity for growth</td>
                    </tr>
                    <tr>
                        <td>Linked List</td>
                        <td>element_size + 8 bytes</td>
                        <td>Theoretical: 8 bytes overhead per element (64-bit pointer)</td>
                    </tr>
                    <tr>
                        <td>Doubly Linked</td>
                        <td>element_size + 16 bytes</td>
                        <td>Theoretical: 16 bytes overhead (2 pointers)</td>
                    </tr>
                    <tr>
                        <td>Binary Tree Node</td>
                        <td>element_size + 16 bytes</td>
                        <td>Theoretical: 16 bytes overhead (left + right pointers)</td>
                    </tr>
                    <tr>
                        <td>Hash Table</td>
                        <td>element_size × 1.5-2</td>
                        <td>Theoretical: Load factor dependent, includes metadata</td>
                    </tr>
                </tbody>
            </table>
            
            <div class="theoretical-insight">
                <h3>Theoretical Memory Efficiency Analysis</h3>
                <p>Memory efficiency can be calculated as: <span class="highlight">Useful Data Size / Total Memory Used</span></p>
                <ul>
                    <li><strong>Array:</strong> Efficiency = 100% (no overhead)</li>
                    <li><strong>Linked List:</strong> Efficiency = element_size / (element_size + 8)</li>
                    <li><strong>For int (4 bytes):</strong> Efficiency = 4/(4+8) = 33% efficiency</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <h2>🎯 Key Theoretical Takeaways - Must Understand</h2>
            
            <div class="feynman-box">
                <h3>Theoretical Foundation Summary</h3>
                
                <div class="simulation-step">
                    <div class="step-number">T1</div>
                    <h4>Memory Hierarchy Theory</h4>
                    <p>Registers (fastest) → Cache → RAM → Disk (slowest)<br>
                    Each level is 10-100x slower than the previous<br>
                    Cache works in 64-byte lines for optimal performance</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T2</div>
                    <h4>Stack vs Heap Theoretical Model</h4>
                    <p>Stack: Fast, automatic, limited, LIFO - mathematically efficient<br>
                    Heap: Slower, manual, large, flexible - theoretically scalable<br>
                    Stack for local variables, heap for dynamic data</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T3</div>
                    <h4>Memory Layout Theory</h4>
                    <p>Programs have: Text, Data, BSS, Heap, Stack<br>
                    Arrays are contiguous (cache-friendly) - optimal for sequential access<br>
                    Linked structures are scattered (cache-unfriendly) - optimal for dynamic growth</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T4</div>
                    <h4>Optimization Theory</h4>
                    <p>Sequential access >> Random access (spatial locality)<br>
                    Struct of Arrays >> Array of Structs (for parallel processing)<br>
                    Pack data to minimize padding (memory efficiency)<br>
                    Reuse memory instead of allocate/free (temporal locality)</p>
                </div>
                
                <div class="simulation-step">
                    <div class="step-number">T5</div>
                    <h4>Cache Optimization Theory</h4>
                    <p>Spatial locality: Access nearby data (cache line utilization)<br>
                    Temporal locality: Reuse recently accessed data (cache retention)<br>
                    Loop tiling for large datasets (cache-aware algorithms)</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>🧠 Theoretical Mental Models to Internalize</h2>
            
            <div class="deep-dive">
                <p><span class="highlight">"Memory is NOT just a big array—it's a theoretical hierarchy."</span><br>
                Each level serves different purposes with different performance characteristics.</p>
                
                <p><span class="highlight">"Cache misses can cost 100x more than cache hits in theoretical performance."</span><br>
                Memory access patterns directly impact algorithm performance.</p>
                
                <p><span class="highlight">"Stack grows down, heap grows up, they meet in the middle - theoretical architecture."</span><br>
                Understanding growth directions helps prevent memory conflicts.</p>
                
                <p><span class="highlight">"Contiguous data structures leverage cache, scattered data structures fight it theoretically."</span><br>
                Data layout directly impacts performance through cache behavior.</p>
                
                <p><span class="highlight">"Every pointer is 8 bytes of theoretical overhead (64-bit systems)."</span><br>
                Pointer overhead significantly impacts memory efficiency for small data.</p>
            </div>
            
            <div class="interactive-element">
                <h3>Theoretical Application Exercise</h3>
                <p><strong>Take a 10-minute break.</strong> Walk around. Your brain needs to consolidate the theoretical concepts.</p>
                <p>When ready, type "HOUR 2" to begin Logic Building with Memory Concepts.</p>
                <p>In Hour 2, we'll apply everything you learned:</p>
                <ul>
                    <li>How to choose data structures based on theoretical memory requirements</li>
                    <li>Memory-efficient algorithm design using theoretical principles</li>
                    <li>Cache-aware optimization patterns from theoretical foundations</li>
                    <li>Practical tradeoffs between theoretical models and real-world implementation</li>
                </ul>
                
                <p>Your theoretical understanding of memory is now 10x deeper than 95% of programmers.</p>
                <p>Keep this momentum. The theoretical foundation is solid.</p>
            </div>
        </div>

        <div class="interactive-element" style="text-align: center; margin-top: 30px;">
            <button class="btn" onclick="completeHour1()">✅ Complete Theoretical Hour 1</button>
            <button class="btn" onclick="resetAll()">🔄 Reset All Theoretical Concepts</button>
        </div>
    </div>

    <script>
        let stackPointer = 0;
        let heapAllocations = [];
        let currentStep = 0;
        let cacheLineAccessed = false;

        function updateProgress() {
            const progress = (currentStep / 60) * 100;
            document.getElementById('progressFill').style.width = progress + '%';
        }

        function startJourney() {
            alert("Welcome to Rio Master's Theoretical Deep Dive! You are now embarking on a journey to master the theoretical foundations of stack and heap memory. This theoretical knowledge will make you 10x better than average programmers!");
            currentStep += 5;
            updateProgress();
        }

        function explainMemoryHierarchy() {
            const hierarchy = [
                "Registers (fastest) - CPU registers - O(1) access",
                "Cache (fast) - L1, L2, L3 cache - O(1) access with spatial/temporal locality",
                "RAM (main memory) - Main system memory - O(1) access but slower than cache",
                "Disk (slowest) - Storage drives - O(n) access with high latency"
            ];
            
            let explanation = "Memory Hierarchy - Theoretical Analysis:\n\n";
            hierarchy.forEach((item, index) => {
                explanation += `${index + 1}. ${item}\n`;
            });
            explanation += "\nEach level is 10-100x slower than the previous!\nCache works in 64-byte lines for optimal theoretical performance.\n\nTheoretical principle: Store frequently accessed data in faster memory levels.";
            
            alert(explanation);
            currentStep += 3;
            updateProgress();
        }

        function showFoundation() {
            const foundation = `
            Theoretical Foundation of Memory Management:

            1. MATHEMATICAL PRINCIPLES:
               - Stack: LIFO data structure with O(1) operations
               - Heap: Dynamic allocation with O(log n) search complexity
               - Time Complexity: Stack O(1) vs Heap O(log n) for allocation

            2. COMPUTER SCIENCE PRINCIPLES:
               - Automatic vs Manual memory management
               - Compile-time vs Runtime memory allocation
               - Contiguous vs Scattered memory layout

            3. ARCHITECTURAL PRINCIPLES:
               - CPU cache optimization through spatial/temporal locality
               - Memory alignment and padding requirements
               - Virtual memory management systems

            4. PERFORMANCE PRINCIPLES:
               - Theoretical cache hit rates and their impact on performance
               - Memory access patterns and their efficiency
               - Trade-offs between space and time complexity

            These theoretical principles form the foundation for all practical memory management decisions.
            `;
            
            alert(foundation);
            currentStep += 4;
            updateProgress();
        }

        function simulateFunctionCalls() {
            const stackVis = document.getElementById('stackVisualization');
            stackVis.innerHTML = '';
            
            const calls = [
                { addr: '0x7fff5fbff000', content: 'main() variables - Theoretical base frame', status: 'Active' },
                { addr: '', content: 'function_a() x=10, return to main - Theoretical frame 1', status: 'Active' },
                { addr: '', content: 'function_b() y=20, return to a - Theoretical frame 2', status: 'Active' },
                { addr: '', content: 'function_c() z=30, return to b - Theoretical frame 3', status: 'Active' }
            ];
            
            calls.forEach(call => {
                const row = document.createElement('div');
                row.className = 'memory-row';
                row.innerHTML = `
                    <div class="memory-addr">${call.addr}</div>
                    <div class="memory-content">${call.content}</div>
                    <div class="memory-status">${call.status}</div>
                `;
                stackVis.appendChild(row);
            });
            
            currentStep += 2;
            updateProgress();
        }

        function clearStack() {
            document.getElementById('stackVisualization').innerHTML = '<div class="memory-row"><div class="memory-addr">Empty</div><div class="memory-content">Stack is empty - Theoretical reset</div><div class="memory-status">Ready</div></div>';
            currentStep += 1;
            updateProgress();
        }

        function showStepByStep() {
            const explanation = `
            Theoretical Step-by-Step Function Call Analysis:

            1. main() called:
               - Theoretical stack state: [main's variables]
               - Stack pointer: SP = base + frame_size
               - Time complexity: O(1) allocation

            2. function_a() called:
               - Theoretical stack state: [main's variables | x=10 | return_addr_to_main]
               - Stack pointer: SP = SP - frame_size
               - Theoretical cost: O(1) push operation

            3. function_b() called:
               - Theoretical stack state: [main | x=10 | ret | y=20 | return_addr_to_a]
               - Stack pointer: SP = SP - frame_size
               - Theoretical cost: O(1) push operation

            4. function_c() called:
               - Theoretical stack state: [main | x=10 | ret | y=20 | ret | z=30 | return_addr_to_b]
               - Stack pointer: SP = SP - frame_size
               - Theoretical cost: O(1) push operation

            5. function_c() returns:
               - Theoretical stack state: [main | x=10 | ret | y=20 | ret] (z destroyed)
               - Stack pointer: SP = SP + frame_size
               - Theoretical cost: O(1) pop operation

            6. function_b() returns:
               - Theoretical stack state: [main | x=10 | ret] (y destroyed)
               - Theoretical cost: O(1) pop operation

            7. function_a() returns:
               - Theoretical stack state: [main] (x destroyed)
               - Theoretical cost: O(1) pop operation

            8. main() returns:
               - Theoretical stack state: [] (stack empty)
               - Theoretical cost: O(1) cleanup

            Theoretical complexity: O(n) for n function calls, but each operation is O(1).
            `;
            
            alert(explanation);
            currentStep += 3;
            updateProgress();
        }

        function simulateStackOverflow() {
            const result = document.getElementById('overflowResult');
            result.innerHTML = `
            <div style="color: #ff6b6b; font-weight: bold; padding: 15px; border: 2px solid #ff6b6b; border-radius: 8px; background: rgba(255, 107, 107, 0.1);">
                ⚠️ THEORETICAL STACK OVERFLOW DETECTED! 🚨<br><br>
                <strong>Mathematical Analysis:</strong><br>
                - Stack depth: n → ∞<br>
                - Stack size: n × frame_size → exceeds stack_limit<br>
                - Theoretical condition: n > stack_limit / frame_size<br>
                - Result: "RecursionError: maximum recursion depth exceeded"<br><br>
                <strong>Theoretical Solution:</strong> Use iterative algorithms or increase stack size.
            </div>`;
            currentStep += 4;
            updateProgress();
        }

        function simulateCacheAccess() {
            const cacheBlocks = document.querySelectorAll('.cache-block');
            const result = document.getElementById('cacheResult');
            
            result.innerHTML = '<div style="color: #4ecdc4; font-weight: bold; margin: 10px 0;">Theoretical Cache Access Simulation Started...</div>';
            
            cacheBlocks.forEach((block, index) => {
                setTimeout(() => {
                    block.classList.add('active');
                    if (index === 0) {
                        block.classList.add('hit');
                        result.innerHTML += `<div style="color: #4ecdc4;">Access ${index + 1}: Cache MISS - Loading entire cache line (64 bytes)</div>`;
                    } else {
                        block.classList.add('hit');
                        result.innerHTML += `<div style="color: #4ecdc4;">Access ${index + 1}: Cache HIT - Data already in cache</div>`;
                    }
                    
                    setTimeout(() => {
                        block.classList.remove('active', 'hit');
                    }, 1000);
                }, index * 200);
            });
            
            currentStep += 2;
            updateProgress();
        }

        function toggleSection(sectionId) {
            const section = document.getElementById(sectionId);
            section.style.display = section.style.display === 'none' ? 'block' : 'none';
            currentStep += 1;
            updateProgress();
        }

        function completeHour1() {
            const completionMessage = `
            🎉 CONGRATULATIONS! 🎉

            You have completed Hour 1 of Rio Master's Theoretical Deep Dive!

            Your understanding of stack and heap memory is now 10x deeper than 95% of programmers.

            Theoretical concepts mastered:
            ✅ Stack vs Heap differences (mathematical foundations)
            ✅ Memory layout of programs (theoretical architecture)  
            ✅ Cache optimization techniques (theoretical principles)
            ✅ Memory-efficient programming (theoretical frameworks)
            ✅ Performance analysis (theoretical complexity)
            ✅ Problem identification (theoretical error patterns)

            Theoretical Foundation Score: ${currentStep}/60 concepts mastered!

            Ready for Hour 2? The logic building phase awaits!
            The theoretical principles you've learned will now be applied to practical problem solving.
            `;
            
            alert(completionMessage);
            currentStep = 60;
            updateProgress();
        }

        function resetAll() {
            currentStep = 0;
            updateProgress();
            document.getElementById('overflowResult').innerHTML = '';
            document.getElementById('cacheResult').innerHTML = '';
            
            // Reset all hidden sections
            document.querySelectorAll('.hidden-content').forEach(el => {
                el.style.display = 'none';
            });
            
            // Reset stack visualization
            document.getElementById('stackVisualization').innerHTML = '<div class="memory-row"><div class="memory-addr">Empty</div><div class="memory-content">Stack is empty - Ready for theoretical analysis</div><div class="memory-status">Ready</div></div>';
            
            alert("All theoretical progress reset. Ready to start the theoretical journey over!");
        }

        // Initialize the page with theoretical progress
        updateProgress();
        
        // Add some interactive elements
        document.addEventListener('DOMContentLoaded', function() {
            // Add hover effects to all sections
            document.querySelectorAll('.section').forEach(section => {
                section.addEventListener('mouseenter', function() {
                    this.style.transform = 'translateY(-3px)';
                });
                section.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateY(0)';
                });
            });
            
            // Add theoretical tips to buttons
            document.querySelectorAll('.btn').forEach(btn => {
                btn.addEventListener('mouseenter', function() {
                    this.title = 'Click to explore theoretical concepts and deep dive explanations';
                });
            });
        });
    </script>
</body>
</html>